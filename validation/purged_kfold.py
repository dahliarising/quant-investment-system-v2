"""
Purged K-Fold Cross Validation
- ì‹œê³„ì—´ ë°ì´í„°ì˜ ë¯¸ë˜ ì •ë³´ ëˆ„ìˆ˜ ë°©ì§€
- Embargo ê¸°ê°„ í¬í•¨
- Advances in Financial Machine Learning (Marcos Lopez de Prado) ì°¸ê³ 
"""
import numpy as np
import pandas as pd
from typing import List, Tuple, Optional
from datetime import timedelta


class PurgedKFold:
    """
    Purged K-Fold Cross Validation
    
    ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ ê°„ ì •ë³´ ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´:
    1. ê²€ì¦ ì„¸íŠ¸ ì§ì „ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì œê±° (Purge)
    2. ê²€ì¦ ì„¸íŠ¸ ì§í›„ì— ì¶”ê°€ ê°­ ì„¤ì • (Embargo)
    """
    
    def __init__(
        self,
        n_splits: int = 5,
        purge_days: int = 30,
        embargo_days: int = 5
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            n_splits: fold ê°œìˆ˜
            purge_days: ì œê±°í•  ê¸°ê°„ (ì¼)
            embargo_days: ì¶”ê°€ ê°­ ê¸°ê°„ (ì¼)
        """
        self.n_splits = n_splits
        self.purge_days = purge_days
        self.embargo_days = embargo_days
        
    def split(
        self,
        X: pd.DataFrame,
        y: Optional[pd.Series] = None
    ) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        í•™ìŠµ/ê²€ì¦ ì¸ë±ìŠ¤ ìƒì„±
        
        Args:
            X: íŠ¹ì§• ë°ì´í„°í”„ë ˆì„ (indexëŠ” datetime)
            y: íƒ€ê²Ÿ (ì‚¬ìš© ì•ˆí•¨, sklearn í˜¸í™˜ì„±)
            
        Returns:
            (train_indices, test_indices) ë¦¬ìŠ¤íŠ¸
        """
        if not isinstance(X.index, pd.DatetimeIndex):
            raise ValueError("Index must be DatetimeIndex")
        
        dates = X.index.unique().sort_values()
        n_samples = len(dates)
        
        # ê° foldì˜ í¬ê¸°
        fold_size = n_samples // self.n_splits
        
        splits = []
        
        for fold in range(self.n_splits):
            # ê²€ì¦ ì„¸íŠ¸ ë²”ìœ„
            test_start_idx = fold * fold_size
            test_end_idx = (fold + 1) * fold_size if fold < self.n_splits - 1 else n_samples
            
            test_start_date = dates[test_start_idx]
            test_end_date = dates[test_end_idx - 1]
            
            # Purge ê¸°ê°„ ê³„ì‚°
            purge_start_date = test_start_date - timedelta(days=self.purge_days)
            
            # Embargo ê¸°ê°„ ê³„ì‚°
            embargo_end_date = test_end_date + timedelta(days=self.embargo_days)
            
            # í•™ìŠµ ì„¸íŠ¸: purge ì´ì „ + embargo ì´í›„
            train_mask = (
                (dates < purge_start_date) |  # purge ì´ì „
                (dates > embargo_end_date)     # embargo ì´í›„
            )
            
            # ê²€ì¦ ì„¸íŠ¸
            test_mask = (dates >= test_start_date) & (dates <= test_end_date)
            
            # ì¸ë±ìŠ¤ ë³€í™˜
            train_dates = dates[train_mask]
            test_dates = dates[test_mask]
            
            train_indices = X.index.isin(train_dates)
            test_indices = X.index.isin(test_dates)
            
            # numpy arrayë¡œ ë³€í™˜
            train_idx = np.where(train_indices)[0]
            test_idx = np.where(test_indices)[0]
            
            splits.append((train_idx, test_idx))
            
            # ì •ë³´ ì¶œë ¥
            print(f"\nFold {fold + 1}/{self.n_splits}:")
            print(f"  Train: {len(train_idx):,} samples")
            print(f"    Before purge: {train_dates[train_dates < purge_start_date].min()} ~ "
                  f"{train_dates[train_dates < purge_start_date].max()}")
            if len(train_dates[train_dates > embargo_end_date]) > 0:
                print(f"    After embargo: {train_dates[train_dates > embargo_end_date].min()} ~ "
                      f"{train_dates[train_dates > embargo_end_date].max()}")
            print(f"  Test:  {len(test_idx):,} samples ({test_start_date.date()} ~ {test_end_date.date()})")
            print(f"  Purge period: {self.purge_days} days")
            print(f"  Embargo period: {self.embargo_days} days")
        
        return splits
    
    def get_n_splits(self) -> int:
        """Fold ê°œìˆ˜ ë°˜í™˜"""
        return self.n_splits


class TimeSeriesSplit:
    """
    ì‹œê³„ì—´ ë¶„í•  (í™•ì¥ ìœˆë„ìš°)
    - í•™ìŠµ ì„¸íŠ¸ê°€ ì ì  ì»¤ì§
    - ê²€ì¦ ì„¸íŠ¸ëŠ” í•­ìƒ ë¯¸ë˜
    """
    
    def __init__(
        self,
        n_splits: int = 5,
        min_train_size: Optional[int] = None,
        test_size: Optional[int] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            n_splits: fold ê°œìˆ˜
            min_train_size: ìµœì†Œ í•™ìŠµ í¬ê¸°
            test_size: ê²€ì¦ í¬ê¸° (Noneì´ë©´ ìë™)
        """
        self.n_splits = n_splits
        self.min_train_size = min_train_size
        self.test_size = test_size
        
    def split(
        self,
        X: pd.DataFrame,
        y: Optional[pd.Series] = None
    ) -> List[Tuple[np.ndarray, np.ndarray]]:
        """í•™ìŠµ/ê²€ì¦ ì¸ë±ìŠ¤ ìƒì„±"""
        n_samples = len(X)
        
        # ê²€ì¦ í¬ê¸° ê²°ì •
        if self.test_size is None:
            test_size = n_samples // (self.n_splits + 1)
        else:
            test_size = self.test_size
        
        # ìµœì†Œ í•™ìŠµ í¬ê¸°
        if self.min_train_size is None:
            min_train_size = test_size
        else:
            min_train_size = self.min_train_size
        
        splits = []
        
        for i in range(self.n_splits):
            # ê²€ì¦ ì„¸íŠ¸
            test_start = min_train_size + (i * test_size)
            test_end = test_start + test_size
            
            if test_end > n_samples:
                break
            
            # í•™ìŠµ ì„¸íŠ¸ (ì²˜ìŒë¶€í„° ê²€ì¦ ì§ì „ê¹Œì§€)
            train_idx = np.arange(0, test_start)
            test_idx = np.arange(test_start, min(test_end, n_samples))
            
            splits.append((train_idx, test_idx))
            
            print(f"\nFold {i + 1}/{self.n_splits}:")
            print(f"  Train: {len(train_idx):,} samples (index 0 ~ {test_start - 1})")
            print(f"  Test:  {len(test_idx):,} samples (index {test_start} ~ {test_end - 1})")
        
        return splits


class ValidationMetrics:
    """ê²€ì¦ ë©”íŠ¸ë¦­ìŠ¤"""
    
    @staticmethod
    def rank_ic(predictions: pd.Series, actuals: pd.Series) -> float:
        """
        Rank IC (Information Coefficient)
        - ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ Spearman ìƒê´€ê³„ìˆ˜
        
        Args:
            predictions: ì˜ˆì¸¡ê°’
            actuals: ì‹¤ì œê°’
            
        Returns:
            Rank IC
        """
        return predictions.corr(actuals, method='spearman')
    
    @staticmethod
    def hit_rate(predictions: pd.Series, actuals: pd.Series) -> float:
        """
        Hit Rate (ë°©í–¥ ì •í™•ë„)
        
        Args:
            predictions: ì˜ˆì¸¡ê°’
            actuals: ì‹¤ì œê°’
            
        Returns:
            Hit rate (0~1)
        """
        pred_direction = (predictions > 0).astype(int)
        actual_direction = (actuals > 0).astype(int)
        
        return (pred_direction == actual_direction).mean()
    
    @staticmethod
    def sharpe_ratio(returns: pd.Series, risk_free_rate: float = 0.02) -> float:
        """
        Sharpe Ratio
        
        Args:
            returns: ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ
            risk_free_rate: ë¬´ìœ„í—˜ ìˆ˜ìµë¥  (ì—°ìœ¨)
            
        Returns:
            Sharpe ratio
        """
        excess_returns = returns - risk_free_rate / 252
        
        if excess_returns.std() == 0:
            return 0.0
        
        return np.sqrt(252) * excess_returns.mean() / excess_returns.std()
    
    @staticmethod
    def max_drawdown(cumulative_returns: pd.Series) -> float:
        """
        Maximum Drawdown
        
        Args:
            cumulative_returns: ëˆ„ì  ìˆ˜ìµë¥ 
            
        Returns:
            Maximum drawdown (ìŒìˆ˜)
        """
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max
        
        return drawdown.min()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    print("=" * 80)
    print("Purged K-Fold Cross Validation ì˜ˆì œ")
    print("=" * 80)
    
    # ë‚ ì§œ ë²”ìœ„
    dates = pd.date_range('2020-01-01', '2024-12-31', freq='D')
    
    # íŠ¹ì§• ë°ì´í„°
    np.random.seed(42)
    X = pd.DataFrame({
        'feature_1': np.random.randn(len(dates)),
        'feature_2': np.random.randn(len(dates)),
        'feature_3': np.random.randn(len(dates))
    }, index=dates)
    
    # íƒ€ê²Ÿ (30ì¼ í›„ ìˆ˜ìµë¥ )
    y = pd.Series(np.random.randn(len(dates)) * 0.1, index=dates)
    
    print(f"\në°ì´í„° í¬ê¸°: {len(X):,} samples")
    print(f"ê¸°ê°„: {X.index.min().date()} ~ {X.index.max().date()}")
    
    # Purged K-Fold
    print("\n" + "=" * 80)
    print("Purged K-Fold (n_splits=5, purge=30ì¼, embargo=5ì¼)")
    print("=" * 80)
    
    pkf = PurgedKFold(n_splits=5, purge_days=30, embargo_days=5)
    splits = pkf.split(X)
    
    # ê° foldì˜ ì„±ëŠ¥ í‰ê°€ (ì‹œë®¬ë ˆì´ì…˜)
    print("\n" + "=" * 80)
    print("Foldë³„ ì„±ëŠ¥ í‰ê°€ (ì‹œë®¬ë ˆì´ì…˜)")
    print("=" * 80)
    
    for i, (train_idx, test_idx) in enumerate(splits):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        # ê°„ë‹¨í•œ ì„ í˜• ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
        # ì‹¤ì œë¡œëŠ” LightGBM ë“± ì‚¬ìš©
        predictions = y_test + np.random.randn(len(y_test)) * 0.05
        
        # ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        rank_ic = ValidationMetrics.rank_ic(predictions, y_test)
        hit_rate = ValidationMetrics.hit_rate(predictions, y_test)
        
        print(f"\nFold {i + 1}:")
        print(f"  Rank IC: {rank_ic:.4f}")
        print(f"  Hit Rate: {hit_rate:.4f}")
    
    # Time Series Split
    print("\n" + "=" * 80)
    print("Time Series Split (í™•ì¥ ìœˆë„ìš°)")
    print("=" * 80)
    
    tss = TimeSeriesSplit(n_splits=5, min_train_size=365)
    ts_splits = tss.split(X)
    
    # ê²€ì¦ ì„¸íŠ¸ í¬ê¸° ë¹„êµ
    print("\n" + "=" * 80)
    print("ê²€ì¦ ë°©ë²• ë¹„êµ")
    print("=" * 80)
    
    print("\nPurged K-Fold:")
    print(f"  - í•™ìŠµ ì„¸íŠ¸ í¬ê¸°: ë³€ë™ (purge/embargo ì œì™¸)")
    print(f"  - ê²€ì¦ ì„¸íŠ¸ í¬ê¸°: ê· ë“±")
    print(f"  - ë¯¸ë˜ ì •ë³´ ëˆ„ìˆ˜: ë°©ì§€ë¨")
    print(f"  - ìš©ë„: ê¸ˆìœµ ì‹œê³„ì—´ ë°ì´í„°")
    
    print("\nTime Series Split:")
    print(f"  - í•™ìŠµ ì„¸íŠ¸ í¬ê¸°: ì ì§„ì  ì¦ê°€")
    print(f"  - ê²€ì¦ ì„¸íŠ¸ í¬ê¸°: ê³ ì •")
    print(f"  - ë¯¸ë˜ ì •ë³´ ëˆ„ìˆ˜: ë°©ì§€ë¨")
    print(f"  - ìš©ë„: ìˆœì°¨ì  ì‹œê³„ì—´ ì˜ˆì¸¡")
    
    print("\n" + "=" * 80)
    print("âœ… Purged K-Fold êµ¬í˜„ ì™„ë£Œ!")
    print("=" * 80)
    
    print("\nğŸ’¡ ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ:")
    print("""
from validation.purged_kfold import PurgedKFold, ValidationMetrics
from lightgbm import LGBMRegressor

# Purged K-Fold ìƒì„±
pkf = PurgedKFold(n_splits=5, purge_days=30, embargo_days=5)

# êµì°¨ ê²€ì¦
ic_scores = []

for train_idx, test_idx in pkf.split(X):
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    
    # ëª¨ë¸ í•™ìŠµ
    model = LGBMRegressor()
    model.fit(X_train, y_train)
    
    # ì˜ˆì¸¡
    predictions = model.predict(X_test)
    
    # í‰ê°€
    ic = ValidationMetrics.rank_ic(pd.Series(predictions), y_test)
    ic_scores.append(ic)

# í‰ê·  IC
mean_ic = np.mean(ic_scores)
print(f"Mean Rank IC: {mean_ic:.4f}")
    """)
